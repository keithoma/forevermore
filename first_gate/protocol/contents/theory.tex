Taylor's theorem is a powerful tool with many applications in physics, economics and many other fields. But in numerical analysis, we can use the Taylor polynomial to compute approximations for the derivatives of smooth functions.

Let \([a, b] \subset \mathbb{R}\) be a partitioned interval with \(p\) number of grid points, \(f \in C^{\infty}([a, b], \mathbb{R})\) a function, and we will denote with \(h \in \mathbb{R}\), \(h > 0\) the increment of the approximation. Given an \(x \in (a, b)\), we define \(x_{+} := x + h\) and \(x_{-} := x - h\).

By Taylor's theorem \cite{H.Amann} we have
\begin{align}
    f(x_{+}) &= \sum^{\infty}_{n = 0} \frac{f^{n}(x)}{n!} h^n = f(x) + f'(x)h + \frac{f''(x)}{2}h^2 + \dots \label{eq:1}\\
    f(x_{-}) &= \sum^{\infty}_{n = 0} \frac{f^{n}(x)}{n!} (-h)^n = f(x) - f'(x)h + \frac{f''(x)}{2}h^2 + \dots \label{eq:2}
\end{align}
Reformulate this equation and define the numerical approximation of the first derivative to be
\begin{align*}
    D^{(1)}_h (x) := \frac{f(x_{+} - f(x)}{h} = f'(x) + \sum^{\infty}_{n = 2} \frac{f^{(n)} (x)}{n!}h^{n-1} \text{.}
\end{align*}
Adding (\ref{eq:1}) and (\ref{eq:2}) together and reformulating gives us
\begin{align*}
    D^{(2)}_h (x) := \frac{f(x_{+}) + f(x_{-}) - 2f(x)}{h} = f''(x) + \frac{f^(4)(x)h^2}{3 \cdot 4} + \dots \text{.}
\end{align*}
\(D^{(2)}_h\) is the numerical approximation of the second derivative.

Via remainder estimation we have furthermore the rate of convergence
\begin{align*}
    (D^{(1)}_h f) (x) &= f'(x) + \mathcal{O}(h) \\
    (D^{(2)}_h f) (x) &= f''(x) + \mathcal{O}(h^2) \text{.}
\end{align*}

With the maximum norm we can gauge the difference between the analytic and the approximation. Define for \(k = 1, 2\)
\begin{align*}
    e^{(k)}_f (h) = \max_{x_i \in [a, b]} \left| f^{(k)} (x_i) - (D^{(k)}_h f) (x_i)\right| \text{,}
\end{align*}
where \(x_i\) with \(1 \in i \in p\) are the grid points in \([a, b]\).

In essence, the approximation of the derivative converges uniformly to the analytic as the increment \(h\) tends to \(0\). This realization, however, raises the question whether the aforementioned theory still holds true in the digital world of computing where the number line is far from complete. In the world where only finite amount of ones and zeroes may exist, does the approximation still converge to the exact derivative?\\