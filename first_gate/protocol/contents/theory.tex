\section{Theory and Motivation}
As we alluded in the introduction, this protocol studies the behavior of numerical approximations in the digital enviroment. For this, we need to first define how the approximation of a derivative is constructed (section \ref{chap:approximation}), then the nature of numbers used by computers will be adressed (section \ref{cha:machine}).
% Thinking ahead, we will also introduce the concept of conditioning as it will be important when we explain our results.
%
\subsection{Approximation of Derivatives with the Taylor Polynomial} \label{chap:approximation}
Taylor's theorem is a powerful tool with applications in many fields and branches, but in numerical analysis, we use the Taylor polynomial to compute the approximations for the derivatives of smooth functions.

Let \([a, b] \subset \mathbb{R}\) be a partitioned interval with \(p\) number of grid points, \(f \in C^{\infty}([a, b], \mathbb{R})\) a function, and we will denote with \(h \in \mathbb{R}\), \(h > 0\) the increment of the approximations. Given an \(x \in (a, b)\), we define \(x_{+} := x + h\) and \(x_{-} := x - h\).

By Taylor's theorem \cite{H.Amann} we have
\begin{align}
    f(x_{+}) &= \sum^{\infty}_{n = 0} \frac{f^{(n)}(x)}{n!} h^n = f(x) + f'(x)h + \frac{f''(x)}{2}h^2 + \dots \label{eq:1}\\
    f(x_{-}) &= \sum^{\infty}_{n = 0} \frac{f^{(n)}(x)}{n!} (-h)^n = f(x) - f'(x)h + \frac{f''(x)}{2}h^2 + \dots \label{eq:2}
\end{align}
Reformulate this equation and define the numerical approximation of the first derivative to be
\begin{align*}
    (D^{(1)}_h f) (x) := \frac{f(x_{+}) - f(x)}{h} = f'(x) + \sum^{\infty}_{n = 2} \frac{f^{(n)} (x)}{n!}h^{n-1} \text{.}
\end{align*}
Adding (\ref{eq:1}) and (\ref{eq:2}) together and reformulating gives us
\begin{align*}
    (D^{(2)}_h f)(x) := \frac{f(x_{+}) - 2f(x) + f(x_{-})}{h^2} = f''(x) + \frac{f^{(4)}(x)h^2}{3 \cdot 4} + \dots \text{.}
\end{align*}
\(D^{(2)}_h\) is the numerical approximation of the second derivative.

As the remainder of the Taylor polynomial approaches \(0\) for \(h \rightarrow 0\), the approximations uniformly converge to the analytic derivatives. Via remainder estimation, the rate of convergence is
\begin{align*}
    (D^{(1)}_h f) (x) &= f'(x) + \mathcal{O}(h) \\
    (D^{(2)}_h f) (x) &= f''(x) + \mathcal{O}(h^2) \text{.}
\end{align*}

\noindent With the maximum norm we can gauge the difference between the analytic and the approximation. Define for \(k = 1, 2\)
\begin{align*}
    e^{(k)}_f (h) := \max_{x_i \in [a, b]} \left| f^{(k)} (x_i) - (D^{(k)}_h f) (x_i)\right| \text{,}
\end{align*}
where \(x_i\) with \(1 \in i \in p\) are the grid points in \([a, b]\).

\subsection{Machine Numbers}\label{cha:machine}

As mathematicians, we often flirt with the concept of infinity, yet it is questionable if such a thing adhering to our definition of said concept even exists in the physical world. While our understanding about the cosmos is modest, we know for certain that our computers are limited by hardware --- only finitely many \textit{bits}\footnote{Bit stands for \textit{binary digit} and can be thought to represent a logical value, i.e. "true or false" or "0 or 1".} may be used to represent a number. Thus, we cannot compute with the "real" real numbers, we can only use a resembling, but incomplete number system. This number system is called \textit{machine numbers}\footnote{For the whole section, we cite \cite{EWR}.}.

In a computer, every number is stored as a combination of a \textit{significand} and an \textit{exponent} with the \textit{base} \(2\) which are both represented in the binary system as bits. For example, \texttt{float64}, the data type for a floating point number with 64 bits, uses, according to IEEE-754, 1 bit for the sign of the number, 52 bits for the significand, another 1 bit for the sign of the exponent and 10 for the exponent. The number \(1.2345 \in \mathbb{R}\) would then be \(12345 \cdot 10^{-4}\) and in binary,
\begin{align*}
    1.2345 = (11000000111001)_2 \cdot 2^{-(100)_2}\text{.}
\end{align*}
Using \texttt{float64} we are able to represent the number \(12345\) without an error, but as the information we are able to store is finite, not every number on the real number line can be represented precisely. If a number cannot be represented with the given float type, the computer rounds that number to the nearest machine number, hence \textit{rounding error} occurs. But we can estimate the upper bound of the relative error of the rounding procedure which we denote as the machine epsilon \(\epsilon\). For the experiments we will discuss later, we have used \texttt{float64} in Python for which the machine epsilon is
\begin{align*}
    \epsilon = 2^{-52} \approx 2.22 \cdot 10^{-16} \text{.}
\end{align*}

\subsection{Motivation}
In essence, the approximation of the derivative converges uniformly to the analytic as the increment \(h\) tends to \(0\). This realization, however, raises the question whether the aforementioned theory still holds true in the digital world of computing where the number line is far from complete. In the world where only finite amount of ones and zeroes may exist, does the approximation still converge to the exact derivative?\\